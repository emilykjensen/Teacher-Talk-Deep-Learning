{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF 1.14 and Keras 2.2.4 - there are warnings but TF 2+ is difficult with Windows :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('utterance-data-with-labels-binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObsID</th>\n",
       "      <th>UtteranceID</th>\n",
       "      <th>TeacherID</th>\n",
       "      <th>TranscribedUtterance</th>\n",
       "      <th>IsQuestion</th>\n",
       "      <th>IsInstructionalUtterance</th>\n",
       "      <th>IsInstructionalStatement</th>\n",
       "      <th>IsDisciplinaryUtterance</th>\n",
       "      <th>IsDisciplinaryStatement</th>\n",
       "      <th>IsEvaluationFollowupIncluded</th>\n",
       "      <th>...</th>\n",
       "      <th>CombinedAuthCogUptake</th>\n",
       "      <th>CogLevel</th>\n",
       "      <th>Uptake</th>\n",
       "      <th>IsGoalSpecified</th>\n",
       "      <th>IsDisciplinaryTermsPresent</th>\n",
       "      <th>IsInstructionalQuestion</th>\n",
       "      <th>IsDisciplinaryQuestion</th>\n",
       "      <th>IsStudentResponsePresent</th>\n",
       "      <th>Authenticity</th>\n",
       "      <th>IsSerialQuestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sch01_tch01_03_19_18_period03</td>\n",
       "      <td>1</td>\n",
       "      <td>sch01_tch01</td>\n",
       "      <td>oh you mean the</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sch01_tch01_03_19_18_period03</td>\n",
       "      <td>101</td>\n",
       "      <td>sch01_tch01</td>\n",
       "      <td>thank you somebody</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sch01_tch01_03_19_18_period03</td>\n",
       "      <td>102</td>\n",
       "      <td>sch01_tch01</td>\n",
       "      <td>so I'll need some some help reading it</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sch01_tch01_03_19_18_period03</td>\n",
       "      <td>103</td>\n",
       "      <td>sch01_tch01</td>\n",
       "      <td>you will have died from walking across the str...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sch01_tch01_03_19_18_period03</td>\n",
       "      <td>104</td>\n",
       "      <td>sch01_tch01</td>\n",
       "      <td>get a very good soil goes into like that aware...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ObsID  UtteranceID    TeacherID  \\\n",
       "0  sch01_tch01_03_19_18_period03            1  sch01_tch01   \n",
       "1  sch01_tch01_03_19_18_period03          101  sch01_tch01   \n",
       "2  sch01_tch01_03_19_18_period03          102  sch01_tch01   \n",
       "3  sch01_tch01_03_19_18_period03          103  sch01_tch01   \n",
       "4  sch01_tch01_03_19_18_period03          104  sch01_tch01   \n",
       "\n",
       "                                TranscribedUtterance  IsQuestion  \\\n",
       "0                                   oh you mean the            1   \n",
       "1                                thank you somebody            1   \n",
       "2            so I'll need some some help reading it            0   \n",
       "3  you will have died from walking across the str...           0   \n",
       "4  get a very good soil goes into like that aware...           0   \n",
       "\n",
       "   IsInstructionalUtterance  IsInstructionalStatement  \\\n",
       "0                         1                         0   \n",
       "1                         1                         0   \n",
       "2                         1                         1   \n",
       "3                         0                         0   \n",
       "4                         1                         1   \n",
       "\n",
       "   IsDisciplinaryUtterance  IsDisciplinaryStatement  \\\n",
       "0                        1                        0   \n",
       "1                        0                        0   \n",
       "2                        1                        1   \n",
       "3                        0                        0   \n",
       "4                        1                        1   \n",
       "\n",
       "   IsEvaluationFollowupIncluded  ...  CombinedAuthCogUptake  CogLevel  Uptake  \\\n",
       "0                             0  ...                      0         0       0   \n",
       "1                             0  ...                      0         0       0   \n",
       "2                             0  ...                      0         0       0   \n",
       "3                             0  ...                      0         0       0   \n",
       "4                             1  ...                      0         0       0   \n",
       "\n",
       "   IsGoalSpecified  IsDisciplinaryTermsPresent  IsInstructionalQuestion  \\\n",
       "0                0                           0                        1   \n",
       "1                0                           0                        1   \n",
       "2                0                           0                        0   \n",
       "3                0                           0                        0   \n",
       "4                0                           0                        0   \n",
       "\n",
       "   IsDisciplinaryQuestion  IsStudentResponsePresent  Authenticity  \\\n",
       "0                       1                         0             0   \n",
       "1                       0                         0             0   \n",
       "2                       0                         0             0   \n",
       "3                       0                         0             0   \n",
       "4                       0                         0             0   \n",
       "\n",
       "   IsSerialQuestion  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = data['TranscribedUtterance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables to include:** 'IsInstructionalUtterance', 'IsQuestion', 'Authenticity', 'IsEvaluationElaborated', 'CogLevel', 'IsGoalSpecified', 'IsDisciplinaryTermsPresent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['IsInstructionalStatement','IsDisciplinaryUtterance','IsDisciplinaryStatement','IsEvaluationFollowupIncluded','IsEvaluationValencePositive','CombinedAuthCogUptake','Uptake','IsInstructionalQuestion', 'IsDisciplinaryQuestion','IsStudentResponsePresent','IsSerialQuestion'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ObsID', 'UtteranceID', 'TeacherID', 'TranscribedUtterance',\n",
       "       'IsQuestion', 'IsInstructionalUtterance', 'IsEvaluationElaborated',\n",
       "       'CogLevel', 'IsGoalSpecified', 'IsDisciplinaryTermsPresent',\n",
       "       'Authenticity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16977, 7)\n"
     ]
    }
   ],
   "source": [
    "respList = np.array([list(data.iloc[0,4:])])\n",
    "for i in range(1,len(data)):\n",
    "    respList = np.append(respList, [list(data.iloc[i,4:])], axis=0)\n",
    "print(respList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(utterances.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the sequences\n",
    "encoded_docs = t.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12859"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find longest utterance\n",
    "utterance_lengths = []\n",
    "for i in range(len(encoded_docs)):\n",
    "    utterance_lengths.append(len(encoded_docs[i]))\n",
    "\n",
    "# histogram of utterance length\n",
    "#import matplotlib.pyplot as plt\n",
    "#fig, axs = plt.subplots(1, 1, tight_layout=True)\n",
    "#axs.hist(utterance_lengths, bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to max length\n",
    "padded_docs_init = pad_sequences(encoded_docs, maxlen=max(utterance_lengths), padding='post')\n",
    "# trim to 100 words\n",
    "padded_docs = pad_sequences(padded_docs_init, maxlen=100, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11883, 100) train sequences\n",
      "(2547, 100) validation sequences\n",
      "(2547, 100) test sequences\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(padded_docs, respList, test_size=0.15, random_state=45)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=(15/85), random_state=45)\n",
    "print(X_train.shape, 'train sequences')\n",
    "print(X_val.shape, 'validation sequences')\n",
    "print(X_test.shape, 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 64, input_length=100, mask_zero=True))\n",
    "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           823040    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 860,679\n",
      "Trainable params: 860,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chloe\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Train...\n",
      "Train on 11883 samples, validate on 2547 samples\n",
      "Epoch 1/30\n",
      "11883/11883 [==============================] - 1079s 91ms/step - loss: 0.3087 - acc: 0.8831 - val_loss: 0.2804 - val_acc: 0.8917\n",
      "Epoch 2/30\n",
      "11883/11883 [==============================] - 1035s 87ms/step - loss: 0.2532 - acc: 0.9004 - val_loss: 0.2663 - val_acc: 0.8953\n",
      "Epoch 3/30\n",
      "11883/11883 [==============================] - 549s 46ms/step - loss: 0.2165 - acc: 0.9132 - val_loss: 0.2640 - val_acc: 0.8963\n",
      "2547/2547 [==============================] - 15s 6ms/step\n",
      "Test score: 0.2639854897470347\n",
      "Test accuracy: 0.8962925765904718\n",
      "AUROC:  0.8176226834929956\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "batchsz = 4\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.005, mode='min')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batchsz, epochs=30, validation_data=(X_val, y_val), shuffle=True, callbacks=[es])\n",
    "score, acc = model.evaluate(X_val, y_val, batch_size=batchsz)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "#evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_val, y_pred, multi_class='ovo')\n",
    "print('AUROC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model with 2 hidden layers\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size+1, 64, input_length=100, mask_zero=True))\n",
    "model2.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 11883 samples, validate on 2547 samples\n",
      "Epoch 1/30\n",
      "11883/11883 [==============================] - 1031s 87ms/step - loss: 0.2082 - acc: 0.9166 - val_loss: 0.2724 - val_acc: 0.8963\n",
      "Epoch 2/30\n",
      "11883/11883 [==============================] - 1121s 94ms/step - loss: 0.1821 - acc: 0.9268 - val_loss: 0.3014 - val_acc: 0.8913\n",
      "2547/2547 [==============================] - 33s 13ms/step\n",
      "Test score: 0.3014387057536155\n",
      "Test accuracy: 0.891300709541517\n",
      "AUROC:  0.7954303116509999\n"
     ]
    }
   ],
   "source": [
    "#train model 2\n",
    "batchsz = 4\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.005, mode='min')\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model2.fit(X_train, y_train, batch_size=batchsz, epochs=30, validation_data=(X_val, y_val), shuffle=True, callbacks=[es])\n",
    "#evaluate\n",
    "score, acc = model2.evaluate(X_val, y_val, batch_size=batchsz)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "y_pred = model2.predict(X_val)\n",
    "auc = roc_auc_score(y_val, y_pred, multi_class='ovo')\n",
    "print('AUROC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model with 3 hidden layers\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size+1, 64, input_length=100, mask_zero=True))\n",
    "model3.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1))\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 11883 samples, validate on 2547 samples\n",
      "Epoch 1/30\n",
      "11883/11883 [==============================] - 1117s 94ms/step - loss: 0.3050 - acc: 0.8834 - val_loss: 0.2777 - val_acc: 0.8923\n",
      "Epoch 2/30\n",
      "11883/11883 [==============================] - 1069s 90ms/step - loss: 0.2609 - acc: 0.8985 - val_loss: 0.2718 - val_acc: 0.8910\n",
      "Epoch 3/30\n",
      "11883/11883 [==============================] - 1005s 85ms/step - loss: 0.2285 - acc: 0.9096 - val_loss: 0.2780 - val_acc: 0.8975\n",
      "2547/2547 [==============================] - 38s 15ms/step\n",
      "Test score: 0.27804332741649185\n",
      "Test accuracy: 0.8974704344365285\n",
      "AUROC:  0.8040837360744961\n"
     ]
    }
   ],
   "source": [
    "#train model 3\n",
    "batchsz = 4\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.005, mode='min')\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('Train...')\n",
    "model3.fit(X_train, y_train, batch_size=batchsz, epochs=30, validation_data=(X_val, y_val), shuffle=True, callbacks=[es])\n",
    "#evaluate\n",
    "score, acc = model3.evaluate(X_val, y_val, batch_size=batchsz)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "y_pred = model3.predict(X_val)\n",
    "auc = roc_auc_score(y_val, y_pred, multi_class='ovo')\n",
    "print('AUROC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set performance:\n",
      "2547/2547 [==============================] - 56s 22ms/step\n",
      "Test score: 0.265915459223036\n",
      "Test accuracy: 0.896068224028882\n",
      "AUROC:  0.8067285200606203\n"
     ]
    }
   ],
   "source": [
    "#evaluate best model on test set\n",
    "print('Test set performance:')\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batchsz)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test, y_pred, multi_class='ovo')\n",
    "print('AUROC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsQuestion  acc:  0.7006908673654129  roc:  0.7952762215548111\n",
      "IsInstructionalUtterance  acc:  0.7754535532180216  roc:  0.8167905199542567\n",
      "IsEvaluationElaborated  acc:  0.8932626417888863  roc:  0.8196307735203594\n",
      "CogLevel  acc:  0.9409178602821835  roc:  0.8283777766783753\n",
      "IsGoalSpecified  acc:  0.8585785544054341  roc:  0.8086643898471604\n",
      "IsDisciplinaryTermsPresent  acc:  0.8589656794824738  roc:  0.8557216801966189\n",
      "Authenticity acc:  0.9272898375127987  roc:  0.7226382786727614\n"
     ]
    }
   ],
   "source": [
    "print('IsQuestion  acc: ',1-sum(abs(y_test[:,0] - y_pred[:,0]))/len(y_test),' roc: ', roc_auc_score(y_test[:,0], y_pred[:,0]))\n",
    "print('IsInstructionalUtterance  acc: ',1-sum(abs(y_test[:,1] - y_pred[:,1]))/len(y_test),' roc: ', roc_auc_score(y_test[:,1], y_pred[:,1]))\n",
    "print('IsEvaluationElaborated  acc: ',1-sum(abs(y_test[:,2] - y_pred[:,2]))/len(y_test),' roc: ', roc_auc_score(y_test[:,2], y_pred[:,2]))\n",
    "print('CogLevel  acc: ',1-sum(abs(y_test[:,3] - y_pred[:,3]))/len(y_test),' roc: ', roc_auc_score(y_test[:,3], y_pred[:,3]))\n",
    "print('IsGoalSpecified  acc: ',1-sum(abs(y_test[:,4] - y_pred[:,4]))/len(y_test),' roc: ', roc_auc_score(y_test[:,4], y_pred[:,4]))\n",
    "print('IsDisciplinaryTermsPresent  acc: ',1-sum(abs(y_test[:,5] - y_pred[:,5]))/len(y_test),' roc: ', roc_auc_score(y_test[:,5], y_pred[:,5]))\n",
    "print('Authenticity acc: ',1-sum(abs(y_test[:,6] - y_pred[:,6]))/len(y_test),' roc: ', roc_auc_score(y_test[:,6], y_pred[:,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
